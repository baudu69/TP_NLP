{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=10000, suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Téléchargement du dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\Bastien\n",
      "[nltk_data]     Audu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Bastien\n",
      "[nltk_data]     Audu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "train_documents, train_categories = zip(\n",
    "    *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
    "test_documents, test_categories = zip(\n",
    "    *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du corpus : 7769\n"
     ]
    }
   ],
   "source": [
    "print('Taille du corpus : {0:d}'.format(len(train_documents)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Transformation des catégories en vecteurs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les données textuelles ne sont pas directement utilisables par les modèles de machine learning. Il faut donc les transformer en vecteurs de nombres. Pour cela, on utilise la MultiLabelBinarizer de scikit-learn qui transforme les catégories en vecteurs de 0 et 1, chaque colonne correspondant à une catégorie."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_categories)\n",
    "test_labels = mlb.transform(test_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "algos = {\n",
    "    'KNN5': KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='cosine'),\n",
    "    'MLP': MLPClassifier(max_iter=200, random_state=1, alpha=0.001),\n",
    "    'OVSR': OneVsRestClassifier(LinearSVC(random_state=0)),\n",
    "}\n",
    "\n",
    "\n",
    "def run_models(X_train, Y_train, X_test, Y_test, algos):\n",
    "    for algo_name in algos:\n",
    "        model = algos[algo_name]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        scores = roc_auc_score(Y_test, Y_pred)\n",
    "        print('################## {0} #############'.format(algo_name))\n",
    "        print('Aire sous la courbe: {:.3f}%'.format(scores.mean() * 100))\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. TF-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "CV = CountVectorizer(max_features=1000, stop_words='english')\n",
    "CV.fit(train_documents)\n",
    "corpus_train_CV = CV.transform(train_documents)\n",
    "corpus_test_CV = CV.transform(test_documents)\n",
    "\n",
    "TFIDF = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
    "TFIDF.fit(train_documents)\n",
    "corpus_train_tfidf = TFIDF.transform(train_documents)\n",
    "corpus_test_tfidf = TFIDF.transform(test_documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_best_model2(models: dict, x_train, y_train, x_test, y_test):\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    for param in models:\n",
    "        print('################## {0} #############'.format(param))\n",
    "        model = models[param]\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores = roc_auc_score(y_test, y_pred)\n",
    "        print('Aire sous la courbe: {:.3f}%'.format(scores.mean() * 100))\n",
    "        if scores > best_score:\n",
    "            best_score = scores\n",
    "            best_model = model\n",
    "    return best_model, best_score, best_model.get_params()\n",
    "\n",
    "def get_best_model(model, X, y, cv=2, params=None):\n",
    "    grid = GridSearchCV(model, param_grid=params, cv=cv)\n",
    "    grid.fit(X, y)\n",
    "    return grid.best_estimator_, grid.best_params_, grid.best_score_, grid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Exécution des modèles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## knn1 #############\n",
      "Aire sous la courbe: 73.573%\n",
      "################## knn2 #############\n",
      "Aire sous la courbe: 66.886%\n",
      "################## knn3 #############\n",
      "Aire sous la courbe: 70.753%\n",
      "################## knn5 #############\n",
      "Aire sous la courbe: 68.554%\n",
      "################## knn7 #############\n",
      "Aire sous la courbe: 66.638%\n",
      "################## knn9 #############\n",
      "Aire sous la courbe: 65.204%\n",
      "Meilleur modèle KNN : KNeighborsClassifier(n_jobs=-1, n_neighbors=1)\n",
      "Meilleur paramètre KNN : {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "Meilleur score KNN : 0.7357345230752118\n"
     ]
    }
   ],
   "source": [
    "knns = {\n",
    "    'knn1': KNeighborsClassifier(n_neighbors=1, n_jobs=-1),\n",
    "    'knn2': KNeighborsClassifier(n_neighbors=2, n_jobs=-1),\n",
    "    'knn3': KNeighborsClassifier(n_neighbors=3, n_jobs=-1),\n",
    "    'knn5': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'knn7': KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
    "    'knn9': KNeighborsClassifier(n_neighbors=9, n_jobs=-1),\n",
    "}\n",
    "knn_best_model, knn_best_score, knn_best_parameters = get_best_model2(knns, corpus_train_tfidf, train_labels, corpus_test_tfidf, test_labels)\n",
    "print('Meilleur modèle KNN : {0}'.format(knn_best_model))\n",
    "print('Meilleur paramètre KNN : {0}'.format(knn_best_parameters))\n",
    "print('Meilleur score KNN : {0}'.format(knn_best_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## mlp0.001 #############\n",
      "Aire sous la courbe: 59.988%\n",
      "################## mlp0.01 #############\n",
      "Aire sous la courbe: 60.669%\n",
      "################## mlp0.1 #############\n",
      "Aire sous la courbe: 58.471%\n",
      "Meilleur modèle MLP : MLPClassifier(alpha=0.01, hidden_layer_sizes=(20, 10), random_state=1)\n",
      "Meilleur paramètre MLP : {'activation': 'relu', 'alpha': 0.01, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (20, 10), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "Meilleur score MLP : 0.6066935005179654\n"
     ]
    }
   ],
   "source": [
    "mlps = {\n",
    "    'mlp0.001': MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=200, random_state=1, alpha=0.001),\n",
    "    'mlp0.01': MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=200, random_state=1, alpha=0.01),\n",
    "    'mlp0.1': MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=200, random_state=1, alpha=0.1),\n",
    "}\n",
    "\n",
    "best_mlp_model,best_mlp_score, best_mlp_param = get_best_model2(mlps, corpus_train_tfidf, train_labels, corpus_test_tfidf, test_labels)\n",
    "print('Meilleur modèle MLP : {0}'.format(best_mlp_model))\n",
    "print('Meilleur paramètre MLP : {0}'.format(best_mlp_param))\n",
    "print('Meilleur score MLP : {0}'.format(best_mlp_score))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## ovr0.1 #############\n",
      "Aire sous la courbe: 57.656%\n",
      "################## ovr1 #############\n",
      "Aire sous la courbe: 68.476%\n",
      "################## ovr10 #############\n",
      "Aire sous la courbe: 71.530%\n",
      "################## ovr100 #############\n",
      "Aire sous la courbe: 72.174%\n",
      "################## ovr1000 #############\n",
      "Aire sous la courbe: 72.169%\n",
      "Meilleur modèle OVR : OneVsRestClassifier(estimator=LinearSVC(C=100, random_state=0))\n",
      "Meilleur paramètre OVR : {'estimator__C': 100, 'estimator__class_weight': None, 'estimator__dual': True, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__multi_class': 'ovr', 'estimator__penalty': 'l2', 'estimator__random_state': 0, 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator': LinearSVC(C=100, random_state=0), 'n_jobs': None, 'verbose': 0}\n",
      "Meilleur score OVR : 0.7217420965155602\n"
     ]
    }
   ],
   "source": [
    "ovrs = {\n",
    "    'ovr0.1': OneVsRestClassifier(LinearSVC(random_state=0, C=0.1)),\n",
    "    'ovr1': OneVsRestClassifier(LinearSVC(random_state=0, C=1)),\n",
    "    'ovr10': OneVsRestClassifier(LinearSVC(random_state=0, C=10)),\n",
    "    'ovr100': OneVsRestClassifier(LinearSVC(random_state=0, C=100)),\n",
    "    'ovr1000': OneVsRestClassifier(LinearSVC(random_state=0, C=1000)),\n",
    "}\n",
    "\n",
    "best_ovr_model,best_ovr_score, best_ovr_param = get_best_model2(ovrs, corpus_train_tfidf, train_labels, corpus_test_tfidf, test_labels)\n",
    "print('Meilleur modèle OVR : {0}'.format(best_ovr_model))\n",
    "print('Meilleur paramètre OVR : {0}'.format(best_ovr_param))\n",
    "print('Meilleur score OVR : {0}'.format(best_ovr_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On constate que le meilleur modèle va être le OneVsRestClassifier avec un C=1000, il est équivalent au MLP mais avec un temps de calcul plus rapide."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Vectorisation par SVD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "(7769, 100)"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "SVD = TruncatedSVD(n_components=100)\n",
    "SVD.fit(corpus_train_tfidf)\n",
    "corpus_train_SVD = SVD.transform(corpus_train_tfidf)\n",
    "corpus_test_SVD = SVD.transform(corpus_test_tfidf)\n",
    "corpus_train_SVD.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## KNN5 #############\n",
      "Aire sous la courbe: 63.775%\n",
      "\n",
      "################## MLP #############\n",
      "Aire sous la courbe: 65.137%\n",
      "\n",
      "################## OVSR #############\n",
      "Aire sous la courbe: 60.016%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(corpus_train_SVD, train_labels, corpus_test_SVD, test_labels, algos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept #0: vs cts mln 000 loss net shr dlrs profit revs\n",
      "Concept #1: said pct dlrs company billion bank shares mln lt stock\n",
      "Concept #2: cts div qtly record april pay prior dividend sets march\n",
      "Concept #3: billion bank pct stg mln february vs january money trade\n",
      "Concept #4: loss 000 profit trade tonnes pct japan said dollar rate\n",
      "Concept #5: 000 tonnes wheat said sugar net trade export vs ec\n",
      "Concept #6: dlrs tonnes 1986 billion year quarter earnings 1987 january february\n",
      "Concept #7: pct february january 000 shares stock rose stake rate common\n",
      "Concept #8: stg tonnes 000 mln loss wheat bank money market pct\n",
      "Concept #9: 000 dlrs bank billion oper fed money quarter share dollar\n",
      "Concept #10: billion stock split dividend trade tonnes shares common board declared\n",
      "Concept #11: split dividend stock share quarter earnings 1987 declared payable rate\n",
      "Concept #12: oil billion crude gas split 000 opec barrels stock reserves\n",
      "Concept #13: dlrs fed says mln shares offer rate pct week oper\n",
      "Concept #14: trade stg oper shares stake japan dlrs share 000 japanese\n",
      "Concept #15: offer cts share wheat tender stg 1987 profit earnings quarter\n",
      "Concept #16: profit dollar stake shares yen group 1987 exchange mln says\n",
      "Concept #17: fed says customer stg repurchase federal reserves agreements sets funds\n",
      "Concept #18: profit oper excludes tax pct rate dividend gain prime ec\n",
      "Concept #19: offer profit february tender january says share japan dollar merger\n",
      "Concept #20: oper tonnes cts yen dollar japan sugar fed stg unit\n",
      "Concept #21: coffee february ico january dollar oper brazil quotas delegates cocoa\n",
      "Concept #22: profit dlrs ec trade sugar cts bank tonnes qtr prices\n",
      "Concept #23: ec sugar rate european tender tonnes tax community says offer\n",
      "Concept #24: bank merger shares cts savings oper tonnes common federal january\n",
      "Concept #25: gold ounces japan ton reserves feet dividend ore japanese tons\n",
      "Concept #26: dividend march group stake says 31 bank payable sale week\n",
      "Concept #27: coffee 1987 japan pct tonnes april japanese corp ico fed\n",
      "Concept #28: says gold baker rate corp merger march treasury deficit prime\n",
      "Concept #29: split march offer 1987 sets sale bank payout says week\n",
      "Concept #30: 1987 ec gold march dividend 31 coffee tax reserves gas\n",
      "Concept #31: march merger japan 31 1987 ec sales japanese vs yen\n",
      "Concept #32: canadian canada 1987 corn cts sugar price crude mln dividend\n",
      "Concept #33: says sales bank gold ec 1987 january group april company\n",
      "Concept #34: prime raises rate 50 february effective shares mln oper crude\n",
      "Concept #35: sales canadian canada corn quarter coffee shares gold trade gas\n",
      "Concept #36: group american stock cocoa buffer usair acquisition 1986 price says\n",
      "Concept #37: sugar usair twa group department sales 1987 april rate savings\n",
      "Concept #38: corp sales acquisition dividend week says oper stock feb union\n",
      "Concept #39: american corn sugar split corp coffee usda year shares merger\n",
      "Concept #40: usair twa group qtr split piedmont cts mln acquisition pct\n",
      "Concept #41: avg shrs vs says year bank sets gold prices group\n",
      "Concept #42: american 1987 february canadian group rate marks bundesbank tender express\n",
      "Concept #43: sale opec francs cts wheat billion quarter japan shares american\n",
      "Concept #44: gas usair twa 10 share revs unit earnings sugar corp\n",
      "Concept #45: francs net american sugar usair 31 wheat twa 1st rate\n",
      "Concept #46: merger corp wheat bank trade split stake cyclops francs week\n",
      "Concept #47: sale shares american usair tonnes twa vs corp government avg\n",
      "Concept #48: american sugar cts wheat company gas march pct avg trade\n",
      "Concept #49: francs share american group payout sets sales unit union april\n",
      "Concept #50: quarter sale savings federal yen dollar 1st loan deficit stock\n",
      "Concept #51: sugar quarter group cyclops wheat japan prime canada dixons savings\n",
      "Concept #52: marks bundesbank shares german credit year west net union wheat\n",
      "Concept #53: gas february 10 savings week feb francs split japan federal\n",
      "Concept #54: year unit sell american shares cyclops dixons products 25 industries\n",
      "Concept #55: 10 cyclops company corp dixons corn marks 31 group bundesbank\n",
      "Concept #56: corn february francs tender cyclops oil company stock 20 dixons\n",
      "Concept #57: gencorp acquisition general systems corn partners sugar group reserves 1986\n",
      "Concept #58: year 10 baker cts december sale credit acquisition department crude\n",
      "Concept #59: gulf split 15 cyclops december week dixons iran 31 qtly\n",
      "Concept #60: 10 gencorp group general tax trade december share 31 sale\n",
      "Concept #61: china 10 1986 wheat foreign opec offer gulf south american\n",
      "Concept #62: opec payout sale 15 company union sales bpd year 18\n",
      "Concept #63: gulf iran francs merger 4th cocoa payout china trust says\n",
      "Concept #64: cyclops tender new dixons quarterly acquisition american merger group quarter\n",
      "Concept #65: quarterly sets share savings 20 china loan deficit yen opec\n",
      "Concept #66: gulf tax stock baker december coffee payout feb iran january\n",
      "Concept #67: systems merger industries exchange rates says 15 talks plc strike\n",
      "Concept #68: gulf corp gencorp 31 iran general marks prices agreement 10\n",
      "Concept #69: deficit baker 10 acquisition price said opec stake prices market\n",
      "Concept #70: cyclops gencorp dixons 25 china south 20 15 copper sets\n",
      "Concept #71: south rates taiwan 50 surplus board gulf bank tax group\n",
      "Concept #72: 31 quarterly earnings sets savings marks jan corp 30 international\n",
      "Concept #73: 17 china systems 50 baker grain new february rates tax\n",
      "Concept #74: quarter 20 international corn plc unit trust january december wheat\n",
      "Concept #75: 25 week wheat group trust 10 corn taft financial year\n",
      "Concept #76: systems grain board reserves 10 sets computer ships taft cyclops\n",
      "Concept #77: grain 20 acquisition credit qtr 25 rates ships year baker\n",
      "Concept #78: cyclops stake sell earnings dixons payout gencorp agreement lt industries\n",
      "Concept #79: week qtr quarterly 17 april 1986 4th sets price tax\n",
      "Concept #80: international grain sell growth 15 1986 nil 11 japan south\n",
      "Concept #81: 20 price copper grain official sell marks industries april deficit\n",
      "Concept #82: 25 11 30 tender stg official unit board west nil\n",
      "Concept #83: stock 15 marks report offer cyclops cash 30 business quarterly\n",
      "Concept #84: 20 new pacific official export systems share cyclops refinery bpd\n",
      "Concept #85: international china 30 nil 12 trust feb stores systems banks\n",
      "Concept #86: 15 stores year 4th official 11 national qtr united surplus\n",
      "Concept #87: south 17 sets industries department 11 japanese payout business export\n",
      "Concept #88: 16 industries products 17 talks brazil merger grain qtr acquisition\n",
      "Concept #89: industries 30 rates brazil 12 strike gulf oil payout national\n",
      "Concept #90: south 25 unit grain 30 buy bid acquire africa june\n",
      "Concept #91: 12 nil 50 brazil debt official 11 rate banks prices\n",
      "Concept #92: copper 28 24 group rates grain feb unit export report\n",
      "Concept #93: soviet industries copper oil 1987 11 china brazil guilders quarterly\n",
      "Concept #94: buys official 15 march international gain gas bid taiwan 13\n",
      "Concept #95: national international 11 april rate week prices world production company\n",
      "Concept #96: buy 16 nil systems tender sale 13 1st industries board\n",
      "Concept #97: pacific tax industries national 30 prices 15 company taft dlr\n",
      "Concept #98: 17 16 air share stores buy agreement purolator 30 rate\n",
      "Concept #99: 12 11 business 30 acquisition talks 20 south surplus stock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Concept #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "print_top_words(SVD, TFIDF.get_feature_names_out(), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le but ici est de récupérer l'entièreté des mots du corpus et de les vectoriser. On va ensuite utiliser ces vecteurs pour entrainer un modèle de classification.\n",
    "On pourra donc faire de la prédiction d'un mot à partir d'un contexte."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "7769"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "corpus = []\n",
    "# Pour chaque document, on le tokenise (on récupère ses mots (pas les trop courts ou les trop longs)) et on le met dans le corpus\n",
    "for i in range(len(train_documents)):\n",
    "    corpus.append(gensim.utils.simple_preprocess(train_documents[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model_size = 100\n",
    "model = gensim.models.Word2Vec(corpus, vector_size=model_size, sg=0, window=5, min_count=2, workers=cores - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  0\n",
      "Train  1\n",
      "Train  2\n",
      "Train  3\n",
      "Train  4\n",
      "Train  5\n",
      "Train  6\n",
      "Train  7\n",
      "Train  8\n",
      "Train  9\n",
      "Train  10\n",
      "Train  11\n",
      "Train  12\n",
      "Train  13\n",
      "Train  14\n",
      "Train  15\n",
      "Train  16\n",
      "Train  17\n",
      "Train  18\n",
      "Train  19\n",
      "Train  20\n",
      "Train  21\n",
      "Train  22\n",
      "Train  23\n",
      "Train  24\n",
      "Train  25\n",
      "Train  26\n",
      "Train  27\n",
      "Train  28\n",
      "Train  29\n",
      "Train  30\n",
      "Train  31\n",
      "Train  32\n",
      "Train  33\n",
      "Train  34\n",
      "Train  35\n",
      "Train  36\n",
      "Train  37\n",
      "Train  38\n",
      "Train  39\n",
      "Train  40\n",
      "Train  41\n",
      "Train  42\n",
      "Train  43\n",
      "Train  44\n",
      "Train  45\n",
      "Train  46\n",
      "Train  47\n",
      "Train  48\n",
      "Train  49\n",
      "Train  50\n",
      "Train  51\n",
      "Train  52\n",
      "Train  53\n",
      "Train  54\n",
      "Train  55\n",
      "Train  56\n",
      "Train  57\n",
      "Train  58\n",
      "Train  59\n",
      "Train  60\n",
      "Train  61\n",
      "Train  62\n",
      "Train  63\n",
      "Train  64\n",
      "Train  65\n",
      "Train  66\n",
      "Train  67\n",
      "Train  68\n",
      "Train  69\n",
      "Train  70\n",
      "Train  71\n",
      "Train  72\n",
      "Train  73\n",
      "Train  74\n",
      "Train  75\n",
      "Train  76\n",
      "Train  77\n",
      "Train  78\n",
      "Train  79\n",
      "Train  80\n",
      "Train  81\n",
      "Train  82\n",
      "Train  83\n",
      "Train  84\n",
      "Train  85\n",
      "Train  86\n",
      "Train  87\n",
      "Train  88\n",
      "Train  89\n",
      "Train  90\n",
      "Train  91\n",
      "Train  92\n",
      "Train  93\n",
      "Train  94\n",
      "Train  95\n",
      "Train  96\n",
      "Train  97\n",
      "Train  98\n",
      "Train  99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model.train(corpus, total_examples=len(corpus), epochs=1)\n",
    "    print('Train ', i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model.save('./Word2vec_entraine.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "[('nations', 0.7614343),\n ('looks', 0.13128786),\n ('my', 0.041960564),\n ('countries', 0.015430394),\n ('ge', 0.008838033),\n ('sounds', 0.0050462154),\n ('areas', 0.0047625853),\n ('anything', 0.004585588),\n ('things', 0.0044911387),\n ('agreements', 0.0037674212)]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word(['I','like'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exemple ci-dessus : on prédit le mot qui suit \"I like\" dans le corpus et il y a 76% de chance que ce soit \"nations\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def word2vec_generator(texts, model, vector_size):\n",
    "    dict_word2vec = {}\n",
    "    # Pour chaque document, on récupère la moyenne des vecteurs de ses mots\n",
    "    for index, word_list in enumerate(texts):\n",
    "        arr = np.array([0.0 for i in range(0, vector_size)])\n",
    "        nb_word = 0\n",
    "        for word in word_list:\n",
    "            try:\n",
    "                arr += model[word]\n",
    "                nb_word = nb_word + 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if (len(word_list) == 0):\n",
    "            dict_word2vec[index] = arr\n",
    "        else:\n",
    "            dict_word2vec[index] = arr / nb_word\n",
    "    df_word2vec = pd.DataFrame(dict_word2vec).T\n",
    "    return df_word2vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On va ici tokeniser les documents de train et de test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "corpus_train_tokens = pd.Series(train_documents).apply(lambda document: gensim.utils.simple_preprocess(document))\n",
    "corpus_test_tokens = pd.Series(test_documents).apply(lambda document: gensim.utils.simple_preprocess(document))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#On récupère le modèle entrainé qui prédit les mots à partir d'un contexte\n",
    "model_wv_entraine = gensim.models.Word2Vec.load('./Word2vec_entraine.h5')\n",
    "vector_size = model_wv_entraine.vector_size\n",
    "corpus_train_wv_entraine = word2vec_generator(corpus_train_tokens, model_wv_entraine.wv, vector_size)\n",
    "corpus_test_wv_entraine = word2vec_generator(corpus_test_tokens, model_wv_entraine.wv, vector_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(7769, 100)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_wv_entraine.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## RF #############\n",
      "Cross-validation accuracy: 0.1904 (+/- 0.0221)\n",
      "\n",
      "################## KNN #############\n",
      "Cross-validation accuracy: 0.3432 (+/- 0.0705)\n",
      "\n",
      "################## MLP #############\n",
      "Cross-validation accuracy: 0.0094 (+/- 0.0082)\n",
      "\n",
      "################## OVSR #############\n",
      "Cross-validation accuracy: 0.7440 (+/- 0.0274)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(corpus_train_wv_entraine, train_labels, corpus_test_wv_entraine, test_labels, algos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'OVR est le meilleur modèle. On va donc l'utiliser pour prédire les tags des documents de test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "OneVsRestClassifier(estimator=LinearSVC(random_state=0), n_jobs=-1)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LinearSVC(random_state=0), n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LinearSVC(random_state=0), n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(LinearSVC(random_state=0), n_jobs=-1)\n",
    "ovr.fit(corpus_train_wv_entraine, train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On récupère les prédictions pour les documents de test\n",
    "Pour la lecture, chaque ligne correspond à un article. Chaque colonne correspond à un tag. Si la valeur est à 1, c'est que l'article a ce tag."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = ovr.predict(corpus_test_wv_entraine)\n",
    "p_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On va transformer les prédictions en tags à l'aide du MultiLabelBinarizer qui a servi à encoder les tags."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "[('trade',),\n (),\n ('crude',),\n (),\n ('palm-oil', 'veg-oil'),\n ('ship',),\n (),\n ('grain', 'wheat'),\n ('gold',),\n (),\n (),\n ('interest', 'money-fx'),\n (),\n ('ipi',),\n ('trade',),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('bop', 'trade'),\n (),\n ('acq', 'gold'),\n ('ipi', 'jobs'),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n (),\n ('ship', 'trade'),\n (),\n ('sugar',),\n ('sugar',),\n ('acq',),\n ('money-fx',),\n ('crude',),\n ('oilseed', 'palm-oil', 'soybean'),\n ('acq', 'earn'),\n ('acq',),\n ('earn',),\n ('trade',),\n ('acq',),\n ('iron-steel',),\n ('earn',),\n ('ship', 'trade'),\n ('dlr', 'money-fx'),\n ('jobs',),\n ('money-fx',),\n ('acq',),\n ('sugar',),\n ('sugar',),\n ('earn',),\n (),\n ('earn',),\n ('money-fx',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('acq',),\n ('cotton', 'livestock', 'trade'),\n ('earn',),\n ('ship',),\n ('earn',),\n ('ship',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('interest', 'money-fx'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('jobs', 'zinc'),\n ('earn',),\n ('acq',),\n ('earn',),\n (),\n ('earn',),\n ('interest',),\n ('earn',),\n ('sugar',),\n ('money-fx',),\n (),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('sugar',),\n ('earn',),\n ('sugar',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n (),\n ('acq',),\n ('heat',),\n ('grain', 'soybean'),\n ('jobs',),\n ('crude', 'interest', 'money-fx'),\n ('money-fx',),\n ('interest', 'money-fx'),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('livestock', 'trade'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('interest',),\n ('earn',),\n ('earn',),\n ('cocoa',),\n ('interest', 'money-fx'),\n ('grain', 'wheat'),\n ('earn',),\n ('earn',),\n ('grain',),\n ('earn',),\n ('earn',),\n (),\n ('acq',),\n (),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('acq', 'sorghum'),\n ('earn',),\n ('acq',),\n ('oilseed', 'rapeseed'),\n ('earn',),\n ('grain', 'wheat'),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('trade',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('cocoa', 'interest'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n ('earn',),\n ('coffee', 'trade'),\n (),\n ('acq',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('interest',),\n ('earn',),\n ('acq',),\n (),\n ('cotton',),\n ('earn',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('crude', 'ship'),\n ('earn',),\n ('money-fx',),\n ('grain',),\n ('crude',),\n ('acq',),\n ('earn',),\n ('money-fx', 'money-supply'),\n ('earn',),\n ('crude',),\n (),\n ('earn',),\n ('crude', 'earn'),\n ('money-fx',),\n ('livestock',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('coffee', 'ipi', 'iron-steel', 'trade'),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('grain', 'wheat'),\n ('grain', 'wheat'),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('corn', 'grain'),\n ('grain',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('grain',),\n (),\n ('earn',),\n ('acq',),\n ('earn',),\n (),\n ('acq',),\n ('acq', 'earn'),\n ('iron-steel', 'trade'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('nat-gas',),\n ('earn',),\n ('earn', 'nat-gas'),\n ('earn',),\n ('earn',),\n ('coffee', 'soybean'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('crude', 'gas'),\n ('grain',),\n ('crude', 'fuel', 'gas'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('crude', 'gas'),\n ('trade',),\n ('earn',),\n ('earn',),\n ('coffee',),\n ('earn',),\n ('acq',),\n ('money-fx',),\n ('jobs',),\n ('acq', 'crude', 'nat-gas'),\n ('trade',),\n ('alum',),\n (),\n ('money-fx', 'trade'),\n ('interest', 'money-fx'),\n (),\n ('earn',),\n ('crude', 'earn', 'veg-oil'),\n ('interest', 'money-fx'),\n ('bop', 'trade'),\n ('earn',),\n ('grain', 'wheat'),\n ('earn',),\n ('earn',),\n ('sugar',),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('acq',),\n ('earn',),\n (),\n ('coffee', 'interest'),\n (),\n ('earn',),\n ('sugar',),\n (),\n (),\n ('oat', 'sugar'),\n ('acq',),\n ('coffee', 'rubber'),\n ('acq',),\n ('earn',),\n ('bop', 'trade'),\n ('earn',),\n ('bop',),\n ('dlr', 'money-fx'),\n ('money-fx', 'yen'),\n ('money-fx',),\n ('earn',),\n ('crude', 'interest', 'money-fx'),\n ('money-fx',),\n ('interest', 'money-fx'),\n ('sugar',),\n ('trade',),\n (),\n ('money-fx',),\n ('money-fx',),\n ('earn',),\n ('money-fx', 'trade'),\n ('money-fx', 'trade', 'yen'),\n ('money-fx',),\n ('money-fx',),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('sugar',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('gold',),\n ('grain', 'wheat'),\n ('earn',),\n ('earn',),\n ('bop', 'earn'),\n ('acq',),\n ('gold',),\n ('earn',),\n ('money-fx', 'yen'),\n (),\n ('jobs',),\n ('acq', 'alum', 'ipi', 'strategic-metal'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('veg-oil',),\n ('acq',),\n (),\n ('l-cattle', 'livestock'),\n ('money-fx',),\n ('earn',),\n ('earn',),\n ('crude',),\n ('earn',),\n ('dlr', 'money-fx', 'rape-oil', 'yen'),\n ('interest', 'money-fx'),\n ('dlr', 'money-fx'),\n ('acq', 'earn'),\n ('corn', 'grain', 'ship'),\n ('hog', 'livestock'),\n ('earn',),\n (),\n ('money-fx',),\n ('coffee', 'earn'),\n ('acq',),\n (),\n ('acq',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('interest', 'money-fx'),\n ('gnp', 'trade'),\n ('gnp',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('interest',),\n ('acq',),\n ('money-fx',),\n (),\n ('acq',),\n ('earn',),\n ('grain',),\n ('cotton',),\n ('acq', 'earn'),\n ('earn',),\n ('acq',),\n ('grain', 'wheat'),\n ('bop', 'trade'),\n ('ipi',),\n (),\n ('interest',),\n ('interest',),\n ('grain', 'sorghum'),\n ('earn',),\n ('corn', 'grain', 'wheat'),\n ('retail',),\n ('coffee',),\n ('acq', 'earn'),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('interest',),\n ('acq',),\n ('crude', 'heat'),\n ('interest',),\n ('earn',),\n ('interest',),\n ('acq',),\n ('money-fx',),\n ('barley', 'corn', 'grain', 'wheat'),\n (),\n ('money-fx',),\n ('acq',),\n (),\n ('money-fx',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('gnp', 'money-fx'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('gold',),\n (),\n ('bop', 'money-fx', 'trade'),\n ('barley', 'corn', 'grain'),\n ('barley', 'corn', 'grain', 'sorghum'),\n ('earn',),\n (),\n ('earn',),\n ('money-fx',),\n ('acq',),\n ('bop', 'trade'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n (),\n ('corn', 'grain', 'wheat'),\n ('money-fx',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('corn', 'grain'),\n ('earn',),\n ('dlr', 'money-fx'),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('earn',),\n (),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('grain', 'ship'),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('grain',),\n ('oilseed', 'rapeseed'),\n ('earn',),\n ('coffee', 'trade'),\n ('grain',),\n ('ship', 'sugar'),\n ('ship',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('coffee', 'trade'),\n ('acq',),\n ('retail',),\n ('earn',),\n ('grain',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n ('reserves',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('bop', 'trade'),\n ('earn',),\n ('carcass', 'livestock'),\n ('earn',),\n ('earn',),\n ('gold',),\n ('sugar',),\n ('interest',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('gold',),\n ('money-supply',),\n (),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n ('copper',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n (),\n (),\n ('earn',),\n ('grain',),\n ('grain',),\n ('corn', 'grain', 'oat', 'oilseed', 'soybean', 'wheat'),\n ('cocoa', 'corn', 'grain', 'orange'),\n ('corn', 'grain', 'orange', 'sorghum'),\n ('earn',),\n ('earn',),\n ('rapeseed', 'reserves', 'soy-meal', 'sugar', 'wheat'),\n ('orange',),\n ('orange',),\n ('corn', 'grain', 'wheat'),\n ('potato',),\n (),\n ('barley', 'corn', 'grain', 'wheat'),\n ('acq',),\n ('corn', 'grain', 'wheat'),\n ('alum', 'barley', 'copra-cake', 'palm-oil'),\n ('grain', 'wheat'),\n ('grain', 'wheat'),\n ('earn', 'iron-steel', 'ship', 'tea', 'wpi'),\n ('grain', 'wheat'),\n ('grain', 'wheat'),\n ('grain', 'wheat'),\n ('earn', 'veg-oil'),\n (),\n ('grain', 'wheat'),\n ('corn', 'grain', 'rice', 'sorghum'),\n ('cotton', 'grain'),\n ('grain',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('corn', 'grain', 'oilseed', 'soybean'),\n ('acq',),\n ('corn', 'grain', 'wheat'),\n ('acq',),\n ('grain', 'wheat'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('corn', 'grain', 'oilseed', 'soy-oil', 'soybean', 'veg-oil'),\n ('corn', 'grain'),\n ('barley', 'coconut-oil', 'oilseed', 'palm-oil', 'soybean', 'trade'),\n ('earn',),\n ('earn',),\n ('corn', 'veg-oil'),\n ('corn', 'grain', 'oilseed', 'soybean', 'wheat'),\n ('acq',),\n ('earn',),\n ('barley', 'coconut-oil', 'corn', 'grain'),\n ('grain', 'wheat'),\n ('corn', 'grain', 'sorghum'),\n ('acq',),\n ('acq',),\n ('coconut-oil', 'copra-cake', 'oilseed', 'palm-oil', 'soybean'),\n ('coconut-oil',\n  'corn',\n  'meal-feed',\n  'oilseed',\n  'soy-meal',\n  'soybean',\n  'veg-oil'),\n ('coconut-oil', 'oilseed', 'palm-oil', 'soybean', 'veg-oil'),\n ('fuel',),\n ('coconut-oil', 'copra-cake', 'cotton', 'rice', 'veg-oil'),\n ('grain', 'wheat'),\n ('copra-cake', 'corn', 'grain', 'rice', 'veg-oil'),\n ('orange',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('earn',),\n ('crude',),\n ('grain', 'ship'),\n ('earn',),\n ('grain',),\n ('money-supply',),\n (),\n ('barley', 'grain', 'oat', 'sorghum', 'wheat'),\n ('oilseed', 'soybean'),\n ('acq', 'money-fx'),\n ('earn',),\n ('orange',),\n ('acq',),\n ('acq',),\n ('acq', 'crude'),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('cotton',),\n (),\n ('money-supply',),\n ('money-supply',),\n ('earn', 'money-supply'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('money-supply',),\n ('copper',),\n ('money-supply',),\n ('acq',),\n ('acq',),\n ('money-supply',),\n ('acq',),\n ('corn', 'grain', 'wheat'),\n ('acq',),\n ('earn',),\n ('money-fx', 'money-supply'),\n ('crude',),\n ('money-fx',),\n ('crude', 'nat-gas'),\n (),\n ('corn', 'grain', 'sugar'),\n ('earn',),\n ('crude', 'interest', 'money-fx'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('crude', 'interest', 'money-fx'),\n ('acq',),\n ('earn',),\n ('trade',),\n (),\n ('earn',),\n ('money-supply',),\n ('dlr', 'money-fx'),\n ('dlr', 'money-fx'),\n ('dlr', 'money-fx'),\n ('dlr', 'money-fx'),\n ('grain', 'sorghum', 'wheat'),\n (),\n ('interest',),\n ('dlr', 'money-fx'),\n ('ship',),\n ('crude',),\n ('grain', 'rice'),\n ('oilseed', 'palm-oil', 'soybean', 'veg-oil'),\n ('interest', 'money-fx'),\n ('earn',),\n ('trade',),\n ('acq',),\n (),\n ('trade',),\n (),\n ('interest', 'money-fx'),\n ('coffee',),\n (),\n ('grain',),\n ('jobs',),\n ('trade',),\n ('dlr', 'money-fx'),\n ('cotton',),\n ('gnp',),\n ('copper',),\n ('dlr', 'money-fx'),\n (),\n ('coffee',),\n ('acq',),\n (),\n ('earn',),\n ('interest', 'money-fx'),\n ('copper', 'iron-steel'),\n ('copper',),\n ('trade',),\n ('iron-steel', 'trade'),\n ('acq',),\n ('money-fx',),\n ('cpi',),\n ('acq',),\n (),\n ('earn',),\n ('earn',),\n ('ipi',),\n ('dlr', 'money-fx'),\n ('grain', 'wheat'),\n ('acq',),\n (),\n ('grain', 'rice', 'rubber'),\n (),\n ('gold', 'silver'),\n ('interest',),\n ('acq',),\n ('acq',),\n ('gnp',),\n ('acq',),\n ('money-fx',),\n (),\n ('acq',),\n (),\n ('acq', 'crude'),\n (),\n ('gnp',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('interest', 'money-fx'),\n ('alum',),\n ('interest', 'money-fx'),\n ('sugar',),\n ('interest', 'money-fx'),\n ('dlr', 'money-fx'),\n ('trade',),\n ('crude', 'palm-oil', 'veg-oil'),\n ('gold',),\n ('bop', 'ipi'),\n (),\n ('gnp',),\n (),\n ('gnp',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('copper', 'crude', 'gnp', 'gold', 'zinc'),\n (),\n (),\n ('acq',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n (),\n ('gnp', 'trade'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n (),\n ('nat-gas',),\n ('trade',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n (),\n ('money-fx',),\n ('interest', 'money-fx'),\n ('earn',),\n ('hog', 'livestock'),\n ('trade',),\n ('trade',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('grain', 'oilseed', 'ship'),\n ('earn',),\n ('gnp', 'money-fx'),\n ('earn',),\n ('wpi',),\n ('grain', 'wheat'),\n ('interest',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('coffee', 'grain'),\n ('lei',),\n ('money-supply',),\n ('earn',),\n ('earn',),\n ('money-fx',),\n ('acq', 'gold'),\n ('acq',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('earn',),\n ('cpi', 'interest'),\n ('earn',),\n ('earn',),\n ('crude', 'interest', 'money-fx'),\n ('acq',),\n ('earn',),\n ('interest',),\n ('acq',),\n ('lei',),\n ('earn',),\n ('earn',),\n (),\n ('earn',),\n ('livestock',),\n ('earn',),\n (),\n ('earn',),\n ('acq',),\n ('earn',),\n ('sugar',),\n ('interest', 'money-fx'),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('trade',),\n ('grain',),\n ('earn',),\n ('palm-oil', 'veg-oil'),\n ('earn',),\n ('earn',),\n ('crude', 'ship'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq', 'carcass', 'livestock'),\n ('earn',),\n ('interest', 'money-fx'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('interest',),\n ('acq',),\n ('earn',),\n ('cpi',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('acq', 'earn'),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('crude', 'nat-gas'),\n ('earn',),\n ('earn',),\n ('oilseed',),\n ('earn',),\n ('earn',),\n ('crude', 'nat-gas'),\n ('earn',),\n ('earn',),\n (),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn', 'gnp'),\n ('earn',),\n ('nat-gas',),\n ('earn',),\n (),\n ('acq',),\n ('acq',),\n ('acq',),\n ('earn',),\n ('acq', 'livestock'),\n ('acq',),\n ('earn',),\n ('acq',),\n ('corn', 'grain', 'wheat'),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq',),\n ('carcass', 'livestock'),\n ('interest',),\n ('earn',),\n ('earn',),\n ('acq',),\n ('earn',),\n ('acq', 'crude'),\n (),\n ('acq',),\n ('earn',),\n ('earn',),\n ('earn',),\n (),\n (),\n ('earn',),\n ('acq',),\n ...]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.inverse_transform(p_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exemple pratique"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def predict_article(article, model, mlb, ovr):\n",
    "    token_article_test = gensim.utils.simple_preprocess(article)\n",
    "    article_entraine = word2vec_generator([token_article_test], model.wv, vector_size)\n",
    "    predict_article = ovr.predict(article_entraine)\n",
    "    return mlb.inverse_transform(predict_article)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On va ici prédire les tags d'un article récupéré sur internet ici : https://www.centrenaturesante.com/article.php?p_ida=8\n",
    "On le traduit en anglais et on le stocke dans un fichier texte."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "[('grain', 'rice', 'tea', 'trade')]"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_test = open('./article.txt', 'r').read()\n",
    "predict_article(article_test, model_wv_entraine, mlb, ovr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On voit que le modèle prédit bien les tags de l'article."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}