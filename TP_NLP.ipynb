{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=10000, suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Téléchargement du dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\Bastien\n",
      "[nltk_data]     Audu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "train_documents, train_categories = zip(\n",
    "    *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
    "test_documents, test_categories = zip(\n",
    "    *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du corpus : 7769\n"
     ]
    }
   ],
   "source": [
    "print('Taille du corpus : {0:d}'.format(len(train_documents)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Transformation des catégories en vecteurs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_categories)\n",
    "test_labels = mlb.transform(test_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "algos = {\n",
    "    'KNN5': KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='cosine'),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=200, random_state=1, alpha=0.001),\n",
    "    'OVSR': OneVsRestClassifier(LinearSVC(random_state=0)),\n",
    "    # 'ADA': AdaBoostClassifier(n_estimators=100, random_state=0),\n",
    "    # 'GDB': GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n",
    "    # 'BGG': BaggingClassifier(n_estimators=100, random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "def run_models(X_train, Y_train, X_test, Y_test, algos):\n",
    "    for algo_name in algos:\n",
    "        model = algos[algo_name]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        scores = roc_auc_score(Y_test, Y_pred)\n",
    "        print('################## {0} #############'.format(algo_name))\n",
    "        print('Aire sous la courbe: {:.3f}%'.format(scores.mean() * 100))\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. TF-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "CV = CountVectorizer(max_features=1000, stop_words='english')\n",
    "CV.fit(train_documents)\n",
    "corpus_train_CV = CV.transform(train_documents)\n",
    "corpus_test_CV = CV.transform(test_documents)\n",
    "\n",
    "TFIDF = TfidfTransformer()\n",
    "TFIDF.fit(corpus_train_CV)\n",
    "corpus_train_tfidf = TFIDF.transform(corpus_train_CV)\n",
    "corpus_test_tfidf = TFIDF.transform(corpus_test_CV)\n",
    "\n",
    "TFIDF = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "TFIDF.fit(train_documents)\n",
    "corpus_train_tfidf = TFIDF.transform(train_documents)\n",
    "corpus_test_tfidf = TFIDF.transform(test_documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_best_model(model, X, y, cv=5,\n",
    "                   ={}):\n",
    "    grid = GridSearchCV(model, param_grid=params, cv=cv, scoring='roc_auc')\n",
    "    grid.fit(X, y)\n",
    "    return grid.best_estimator_, grid.best_params_, grid.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Exécution des modèles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle KNN : KNeighborsClassifier(metric='cosine', n_jobs=-1, n_neighbors=3)\n",
      "Meilleur paramètre KNN : {'n_neighbors': 3}\n",
      "Meilleur score KNN : nan\n",
      "Meilleur modèle MLP : MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 10), random_state=1)\n",
      "Meilleur paramètre MLP : {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20, 10)}\n",
      "Meilleur score MLP : nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMeilleur paramètre MLP : \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_mlp_param))\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMeilleur score MLP : \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_mlp_score))\n\u001B[1;32m---> 25\u001B[0m best_ovr_model,best_ovr_param, best_ovr_score \u001B[38;5;241m=\u001B[39m \u001B[43mget_best_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mOneVsRestClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLinearSVC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_train_tfidf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams_ovr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMeilleur modèle OVR : \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_ovr_model))\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMeilleur paramètre OVR : \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_ovr_param))\n",
      "Cell \u001B[1;32mIn[8], line 6\u001B[0m, in \u001B[0;36mget_best_model\u001B[1;34m(model, X, y, cv, params)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_best_model\u001B[39m(model, X, y, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, params\u001B[38;5;241m=\u001B[39m{}):\n\u001B[0;32m      5\u001B[0m     grid \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid\u001B[38;5;241m=\u001B[39mparams, cv\u001B[38;5;241m=\u001B[39mcv, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m grid\u001B[38;5;241m.\u001B[39mbest_estimator_, grid\u001B[38;5;241m.\u001B[39mbest_params_, grid\u001B[38;5;241m.\u001B[39mbest_score_\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    907\u001B[0m refit_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 909\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    910\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    911\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\multiclass.py:330\u001B[0m, in \u001B[0;36mOneVsRestClassifier.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    326\u001B[0m columns \u001B[38;5;241m=\u001B[39m (col\u001B[38;5;241m.\u001B[39mtoarray()\u001B[38;5;241m.\u001B[39mravel() \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m Y\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m    327\u001B[0m \u001B[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001B[39;00m\n\u001B[0;32m    328\u001B[0m \u001B[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001B[39;00m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001B[39;00m\n\u001B[1;32m--> 330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_binary\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnot \u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_binarizer_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_binarizer_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_features_in_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mn_features_in_\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[0;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\multiclass.py:83\u001B[0m, in \u001B[0;36m_fit_binary\u001B[1;34m(estimator, X, y, classes)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     82\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m clone(estimator)\n\u001B[1;32m---> 83\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m estimator\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\svm\\_classes.py:274\u001B[0m, in \u001B[0;36mLinearSVC.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    271\u001B[0m check_classification_targets(y)\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n\u001B[1;32m--> 274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[43m_fit_liblinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintercept_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    289\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001B[39;00m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001B[39;00m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m n_iter_\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\svm\\_base.py:1223\u001B[0m, in \u001B[0;36m_fit_liblinear\u001B[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001B[0m\n\u001B[0;32m   1219\u001B[0m y_ind \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrequire(y_ind, requirements\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1221\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m-> 1223\u001B[0m solver_type \u001B[38;5;241m=\u001B[39m \u001B[43m_get_liblinear_solver_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdual\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1224\u001B[0m raw_coef_, n_iter_ \u001B[38;5;241m=\u001B[39m liblinear\u001B[38;5;241m.\u001B[39mtrain_wrap(\n\u001B[0;32m   1225\u001B[0m     X,\n\u001B[0;32m   1226\u001B[0m     y_ind,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1236\u001B[0m     sample_weight,\n\u001B[0;32m   1237\u001B[0m )\n\u001B[0;32m   1238\u001B[0m \u001B[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001B[39;00m\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001B[39;00m\n\u001B[0;32m   1240\u001B[0m \u001B[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001B[39;00m\n\u001B[0;32m   1241\u001B[0m \u001B[38;5;66;03m# srand supports\u001B[39;00m\n",
      "File \u001B[1;32mC:\\var\\nn\\lib\\site-packages\\sklearn\\svm\\_base.py:1062\u001B[0m, in \u001B[0;36m_get_liblinear_solver_type\u001B[1;34m(multi_class, penalty, loss, dual)\u001B[0m\n\u001B[0;32m   1060\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1061\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m solver_num\n\u001B[1;32m-> 1062\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1063\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported set of arguments: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, Parameters: penalty=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m, loss=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m, dual=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;241m%\u001B[39m (error_string, penalty, loss, dual)\n\u001B[0;32m   1065\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True"
     ]
    }
   ],
   "source": [
    "params_knn = {\n",
    "    'n_neighbors': [3, 5, 8],\n",
    "}\n",
    "\n",
    "params_mlp = {\n",
    "    'hidden_layer_sizes': [(20, 10), (20, 20, 10), (20, 20, 20, 10)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "params_ovr = {\n",
    "    'estimator__C': [0.1, 1, 10, 100, 1000],\n",
    "    'estimator__penalty': ['l1', 'l2'],\n",
    "    'estimator__loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "\n",
    "best_knn_model,best_knn_param, best_knn_score = get_best_model(KNeighborsClassifier(n_jobs=-1, metric='cosine'), corpus_train_tfidf, train_labels, params=params_knn)\n",
    "print('Meilleur modèle KNN : {0}'.format(best_knn_model))\n",
    "print('Meilleur paramètre KNN : {0}'.format(best_knn_param))\n",
    "print('Meilleur score KNN : {0}'.format(best_knn_score))\n",
    "best_mlp_model,best_mlp_param, best_mlp_score = get_best_model(MLPClassifier(max_iter=200, random_state=1), corpus_train_tfidf, train_labels, params=params_mlp)\n",
    "print('Meilleur modèle MLP : {0}'.format(best_mlp_model))\n",
    "print('Meilleur paramètre MLP : {0}'.format(best_mlp_param))\n",
    "print('Meilleur score MLP : {0}'.format(best_mlp_score))\n",
    "best_ovr_model,best_ovr_param, best_ovr_score = get_best_model(OneVsRestClassifier(LinearSVC(random_state=0)), corpus_train_tfidf, train_labels, params=params_ovr)\n",
    "print('Meilleur modèle OVR : {0}'.format(best_ovr_model))\n",
    "print('Meilleur paramètre OVR : {0}'.format(best_ovr_param))\n",
    "print('Meilleur score OVR : {0}'.format(best_ovr_score))\n",
    "algos = {\n",
    "    'KNN': best_knn_model,\n",
    "    'MLP': best_mlp_model,\n",
    "    'OVR': best_ovr_model\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "MLPClassifier(random_state=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(random_state=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=200, random_state=1)\n",
    "model.fit(corpus_train_tfidf, train_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6770241338446288"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_labels, model.predict(corpus_test_tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## bestKn #############\n",
      "Aire sous la courbe: 65.214%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(np.array(corpus_train_tfidf.toarray()), train_labels, np.array(corpus_test_tfidf.toarray()), test_labels,\n",
    "           algos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Vectorisation par SVD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "(7769, 100)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "SVD = TruncatedSVD(n_components=100)\n",
    "SVD.fit(corpus_train_tfidf)\n",
    "corpus_train_SVD = SVD.transform(corpus_train_tfidf)\n",
    "corpus_test_SVD = SVD.transform(corpus_test_tfidf)\n",
    "corpus_train_SVD.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## RF #############\n",
      "Cross-validation accuracy: 0.2277 (+/- 0.0325)\n",
      "\n",
      "################## KNN #############\n",
      "Cross-validation accuracy: 0.3364 (+/- 0.0592)\n",
      "\n",
      "################## MLP #############\n",
      "Cross-validation accuracy: -0.0078 (+/- 0.0114)\n",
      "\n",
      "################## OVSR #############\n",
      "Cross-validation accuracy: 0.7659 (+/- 0.0354)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(corpus_train_SVD, train_labels, corpus_test_SVD, test_labels, algos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept #0: vs cts mln 000 loss net shr dlrs profit revs\n",
      "Concept #1: said pct dlrs company billion bank shares mln lt stock\n",
      "Concept #2: cts div qtly record april pay prior dividend sets march\n",
      "Concept #3: billion bank pct stg mln february vs january money trade\n",
      "Concept #4: loss 000 profit trade tonnes pct japan said dollar rate\n",
      "Concept #5: 000 tonnes wheat said sugar net trade export vs ec\n",
      "Concept #6: dlrs tonnes 1986 billion year quarter earnings 1987 january february\n",
      "Concept #7: pct february january 000 shares stock rose stake rate common\n",
      "Concept #8: stg tonnes 000 mln loss wheat bank money market pct\n",
      "Concept #9: 000 dlrs bank billion oper fed money quarter share dollar\n",
      "Concept #10: billion stock split dividend trade tonnes shares common board declared\n",
      "Concept #11: split dividend stock share quarter earnings 1987 declared payable rate\n",
      "Concept #12: oil billion crude gas split 000 opec barrels stock reserves\n",
      "Concept #13: dlrs fed says mln shares offer rate pct week oper\n",
      "Concept #14: trade stg oper shares stake japan dlrs share 000 japanese\n",
      "Concept #15: offer cts share wheat tender stg 1987 profit earnings quarter\n",
      "Concept #16: profit dollar stake shares yen group 1987 exchange mln says\n",
      "Concept #17: fed says customer stg repurchase federal reserves agreements sets funds\n",
      "Concept #18: profit oper excludes tax pct rate dividend gain prime ec\n",
      "Concept #19: offer profit february tender january says share japan dollar merger\n",
      "Concept #20: oper tonnes cts yen dollar japan sugar fed stg unit\n",
      "Concept #21: coffee february ico january dollar oper brazil quotas delegates cocoa\n",
      "Concept #22: profit dlrs ec trade sugar cts bank tonnes qtr prices\n",
      "Concept #23: ec sugar rate european tender tonnes tax community says offer\n",
      "Concept #24: bank merger shares cts savings oper tonnes common federal january\n",
      "Concept #25: gold ounces japan ton reserves feet dividend ore japanese tons\n",
      "Concept #26: dividend march group stake says 31 bank payable sale week\n",
      "Concept #27: coffee 1987 japan pct tonnes april japanese corp ico fed\n",
      "Concept #28: says gold baker rate corp merger march treasury deficit prime\n",
      "Concept #29: split march offer 1987 sets sale bank payout says week\n",
      "Concept #30: 1987 ec gold march dividend 31 coffee tax reserves gas\n",
      "Concept #31: march merger japan 31 1987 ec sales japanese vs yen\n",
      "Concept #32: canadian canada 1987 corn cts sugar price crude mln dividend\n",
      "Concept #33: says sales bank gold ec 1987 january group april company\n",
      "Concept #34: prime raises rate 50 february effective shares mln oper crude\n",
      "Concept #35: sales canadian canada corn quarter coffee shares gold trade gas\n",
      "Concept #36: group american stock cocoa buffer usair acquisition 1986 price says\n",
      "Concept #37: sugar usair twa group department sales 1987 april rate savings\n",
      "Concept #38: corp sales acquisition dividend week says oper stock feb union\n",
      "Concept #39: american corn sugar split corp coffee usda year shares merger\n",
      "Concept #40: usair twa group qtr split piedmont cts mln acquisition pct\n",
      "Concept #41: avg shrs vs says year bank sets gold prices group\n",
      "Concept #42: american 1987 february canadian group rate marks bundesbank tender express\n",
      "Concept #43: sale opec francs cts wheat billion quarter japan shares american\n",
      "Concept #44: gas usair twa 10 share revs unit earnings sugar corp\n",
      "Concept #45: francs net american sugar usair 31 wheat twa 1st rate\n",
      "Concept #46: merger corp wheat bank trade split stake cyclops francs week\n",
      "Concept #47: sale shares american usair tonnes twa vs corp government avg\n",
      "Concept #48: american sugar cts wheat company gas march pct avg trade\n",
      "Concept #49: francs share american group payout sets sales unit union april\n",
      "Concept #50: quarter sale savings federal yen dollar 1st loan deficit stock\n",
      "Concept #51: sugar quarter group cyclops wheat japan prime canada dixons savings\n",
      "Concept #52: marks bundesbank shares german credit year west net union wheat\n",
      "Concept #53: gas february 10 savings week feb francs split japan federal\n",
      "Concept #54: year unit sell american shares cyclops dixons products 25 industries\n",
      "Concept #55: 10 cyclops company corp dixons corn marks 31 group bundesbank\n",
      "Concept #56: corn february francs tender cyclops oil company stock 20 dixons\n",
      "Concept #57: gencorp acquisition general systems corn partners sugar group reserves 1986\n",
      "Concept #58: year 10 baker cts december sale credit acquisition department crude\n",
      "Concept #59: gulf split 15 cyclops december week dixons iran 31 qtly\n",
      "Concept #60: 10 gencorp group general tax trade december share 31 sale\n",
      "Concept #61: china 10 1986 wheat foreign opec offer gulf south american\n",
      "Concept #62: opec payout sale 15 company union sales bpd year 18\n",
      "Concept #63: gulf iran francs merger 4th cocoa payout china trust says\n",
      "Concept #64: cyclops tender new dixons quarterly acquisition american merger group quarter\n",
      "Concept #65: quarterly sets share savings 20 china loan deficit yen opec\n",
      "Concept #66: gulf tax stock baker december coffee payout feb iran january\n",
      "Concept #67: systems merger industries exchange rates says 15 talks plc strike\n",
      "Concept #68: gulf corp gencorp 31 iran general marks prices agreement 10\n",
      "Concept #69: deficit baker 10 acquisition price said opec stake prices market\n",
      "Concept #70: cyclops gencorp dixons 25 china south 20 15 copper sets\n",
      "Concept #71: south rates taiwan 50 surplus board gulf bank tax group\n",
      "Concept #72: 31 quarterly earnings sets savings marks jan corp 30 international\n",
      "Concept #73: 17 china systems 50 baker grain new february rates tax\n",
      "Concept #74: quarter 20 international corn plc unit trust january december wheat\n",
      "Concept #75: 25 week wheat group trust 10 corn taft financial year\n",
      "Concept #76: systems grain board reserves 10 sets computer ships taft cyclops\n",
      "Concept #77: grain 20 acquisition credit qtr 25 rates ships year baker\n",
      "Concept #78: cyclops stake sell earnings dixons payout gencorp agreement lt industries\n",
      "Concept #79: week qtr quarterly 17 april 1986 4th sets price tax\n",
      "Concept #80: international grain sell growth 15 1986 nil 11 japan south\n",
      "Concept #81: 20 price copper grain official sell marks industries april deficit\n",
      "Concept #82: 25 11 30 tender stg official unit board west nil\n",
      "Concept #83: stock 15 marks report offer cyclops cash 30 business quarterly\n",
      "Concept #84: 20 new pacific official export systems share cyclops refinery bpd\n",
      "Concept #85: international china 30 nil 12 trust feb stores systems banks\n",
      "Concept #86: 15 stores year 4th official 11 national qtr united surplus\n",
      "Concept #87: south 17 sets industries department 11 japanese payout business export\n",
      "Concept #88: 16 industries products 17 talks brazil merger grain qtr acquisition\n",
      "Concept #89: industries 30 rates brazil 12 strike gulf oil payout national\n",
      "Concept #90: south 25 unit grain 30 buy bid acquire africa june\n",
      "Concept #91: 12 nil 50 brazil debt official 11 rate banks prices\n",
      "Concept #92: copper 28 24 group rates grain feb unit export report\n",
      "Concept #93: soviet industries copper oil 1987 11 china brazil guilders quarterly\n",
      "Concept #94: buys official 15 march international gain gas bid taiwan 13\n",
      "Concept #95: national international 11 april rate week prices world production company\n",
      "Concept #96: buy 16 nil systems tender sale 13 1st industries board\n",
      "Concept #97: pacific tax industries national 30 prices 15 company taft dlr\n",
      "Concept #98: 17 16 air share stores buy agreement purolator 30 rate\n",
      "Concept #99: 12 11 business 30 acquisition talks 20 south surplus stock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Concept #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "print_top_words(SVD, TFIDF.get_feature_names_out(), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "['bahia',\n 'cocoa',\n 'review',\n 'showers',\n 'continued',\n 'throughout',\n 'the',\n 'week',\n 'in',\n 'the',\n 'bahia',\n 'cocoa',\n 'zone',\n 'alleviating',\n 'the',\n 'drought',\n 'since',\n 'early',\n 'january',\n 'and',\n 'improving',\n 'prospects',\n 'for',\n 'the',\n 'coming',\n 'temporao',\n 'although',\n 'normal',\n 'humidity',\n 'levels',\n 'have',\n 'not',\n 'been',\n 'restored',\n 'comissaria',\n 'smith',\n 'said',\n 'in',\n 'its',\n 'weekly',\n 'review',\n 'the',\n 'dry',\n 'period',\n 'means',\n 'the',\n 'temporao',\n 'will',\n 'be',\n 'late',\n 'this',\n 'year',\n 'arrivals',\n 'for',\n 'the',\n 'week',\n 'ended',\n 'february',\n 'were',\n 'bags',\n 'of',\n 'kilos',\n 'making',\n 'cumulative',\n 'total',\n 'for',\n 'the',\n 'season',\n 'of',\n 'mln',\n 'against',\n 'at',\n 'the',\n 'same',\n 'stage',\n 'last',\n 'year',\n 'again',\n 'it',\n 'seems',\n 'that',\n 'cocoa',\n 'delivered',\n 'earlier',\n 'on',\n 'consignment',\n 'was',\n 'included',\n 'in',\n 'the',\n 'arrivals',\n 'figures',\n 'comissaria',\n 'smith',\n 'said',\n 'there',\n 'is',\n 'still',\n 'some',\n 'doubt',\n 'as',\n 'to',\n 'how',\n 'much',\n 'old',\n 'crop',\n 'cocoa',\n 'is',\n 'still',\n 'available',\n 'as',\n 'harvesting',\n 'has',\n 'practically',\n 'come',\n 'to',\n 'an',\n 'end',\n 'with',\n 'total',\n 'bahia',\n 'crop',\n 'estimates',\n 'around',\n 'mln',\n 'bags',\n 'and',\n 'sales',\n 'standing',\n 'at',\n 'almost',\n 'mln',\n 'there',\n 'are',\n 'few',\n 'hundred',\n 'thousand',\n 'bags',\n 'still',\n 'in',\n 'the',\n 'hands',\n 'of',\n 'farmers',\n 'middlemen',\n 'exporters',\n 'and',\n 'processors',\n 'there',\n 'are',\n 'doubts',\n 'as',\n 'to',\n 'how',\n 'much',\n 'of',\n 'this',\n 'cocoa',\n 'would',\n 'be',\n 'fit',\n 'for',\n 'export',\n 'as',\n 'shippers',\n 'are',\n 'now',\n 'experiencing',\n 'dificulties',\n 'in',\n 'obtaining',\n 'bahia',\n 'superior',\n 'certificates',\n 'in',\n 'view',\n 'of',\n 'the',\n 'lower',\n 'quality',\n 'over',\n 'recent',\n 'weeks',\n 'farmers',\n 'have',\n 'sold',\n 'good',\n 'part',\n 'of',\n 'their',\n 'cocoa',\n 'held',\n 'on',\n 'consignment',\n 'comissaria',\n 'smith',\n 'said',\n 'spot',\n 'bean',\n 'prices',\n 'rose',\n 'to',\n 'to',\n 'cruzados',\n 'per',\n 'arroba',\n 'of',\n 'kilos',\n 'bean',\n 'shippers',\n 'were',\n 'reluctant',\n 'to',\n 'offer',\n 'nearby',\n 'shipment',\n 'and',\n 'only',\n 'limited',\n 'sales',\n 'were',\n 'booked',\n 'for',\n 'march',\n 'shipment',\n 'at',\n 'to',\n 'dlrs',\n 'per',\n 'tonne',\n 'to',\n 'ports',\n 'to',\n 'be',\n 'named',\n 'new',\n 'crop',\n 'sales',\n 'were',\n 'also',\n 'light',\n 'and',\n 'all',\n 'to',\n 'open',\n 'ports',\n 'with',\n 'june',\n 'july',\n 'going',\n 'at',\n 'and',\n 'dlrs',\n 'and',\n 'at',\n 'and',\n 'dlrs',\n 'under',\n 'new',\n 'york',\n 'july',\n 'aug',\n 'sept',\n 'at',\n 'and',\n 'dlrs',\n 'per',\n 'tonne',\n 'fob',\n 'routine',\n 'sales',\n 'of',\n 'butter',\n 'were',\n 'made',\n 'march',\n 'april',\n 'sold',\n 'at',\n 'and',\n 'dlrs',\n 'april',\n 'may',\n 'butter',\n 'went',\n 'at',\n 'times',\n 'new',\n 'york',\n 'may',\n 'june',\n 'july',\n 'at',\n 'and',\n 'dlrs',\n 'aug',\n 'sept',\n 'at',\n 'to',\n 'dlrs',\n 'and',\n 'at',\n 'and',\n 'times',\n 'new',\n 'york',\n 'sept',\n 'and',\n 'oct',\n 'dec',\n 'at',\n 'dlrs',\n 'and',\n 'times',\n 'new',\n 'york',\n 'dec',\n 'comissaria',\n 'smith',\n 'said',\n 'destinations',\n 'were',\n 'the',\n 'covertible',\n 'currency',\n 'areas',\n 'uruguay',\n 'and',\n 'open',\n 'ports',\n 'cake',\n 'sales',\n 'were',\n 'registered',\n 'at',\n 'to',\n 'dlrs',\n 'for',\n 'march',\n 'april',\n 'dlrs',\n 'for',\n 'may',\n 'dlrs',\n 'for',\n 'aug',\n 'and',\n 'times',\n 'new',\n 'york',\n 'dec',\n 'for',\n 'oct',\n 'dec',\n 'buyers',\n 'were',\n 'the',\n 'argentina',\n 'uruguay',\n 'and',\n 'convertible',\n 'currency',\n 'areas',\n 'liquor',\n 'sales',\n 'were',\n 'limited',\n 'with',\n 'march',\n 'april',\n 'selling',\n 'at',\n 'and',\n 'dlrs',\n 'june',\n 'july',\n 'at',\n 'dlrs',\n 'and',\n 'at',\n 'times',\n 'new',\n 'york',\n 'july',\n 'aug',\n 'sept',\n 'at',\n 'dlrs',\n 'and',\n 'at',\n 'times',\n 'new',\n 'york',\n 'sept',\n 'and',\n 'oct',\n 'dec',\n 'at',\n 'times',\n 'new',\n 'york',\n 'dec',\n 'comissaria',\n 'smith',\n 'said',\n 'total',\n 'bahia',\n 'sales',\n 'are',\n 'currently',\n 'estimated',\n 'at',\n 'mln',\n 'bags',\n 'against',\n 'the',\n 'crop',\n 'and',\n 'mln',\n 'bags',\n 'against',\n 'the',\n 'crop',\n 'final',\n 'figures',\n 'for',\n 'the',\n 'period',\n 'to',\n 'february',\n 'are',\n 'expected',\n 'to',\n 'be',\n 'published',\n 'by',\n 'the',\n 'brazilian',\n 'cocoa',\n 'trade',\n 'commission',\n 'after',\n 'carnival',\n 'which',\n 'ends',\n 'midday',\n 'on',\n 'february']"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "corpus = []\n",
    "for i in range(len(train_documents)):\n",
    "    corpus.append(gensim.utils.simple_preprocess(train_documents[i]))\n",
    "corpus[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model_size = 100\n",
    "model = gensim.models.Word2Vec(corpus, vector_size=model_size, sg=0, window=5, min_count=2, workers=cores - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  0\n",
      "Train  1\n",
      "Train  2\n",
      "Train  3\n",
      "Train  4\n",
      "Train  5\n",
      "Train  6\n",
      "Train  7\n",
      "Train  8\n",
      "Train  9\n",
      "Train  10\n",
      "Train  11\n",
      "Train  12\n",
      "Train  13\n",
      "Train  14\n",
      "Train  15\n",
      "Train  16\n",
      "Train  17\n",
      "Train  18\n",
      "Train  19\n",
      "Train  20\n",
      "Train  21\n",
      "Train  22\n",
      "Train  23\n",
      "Train  24\n",
      "Train  25\n",
      "Train  26\n",
      "Train  27\n",
      "Train  28\n",
      "Train  29\n",
      "Train  30\n",
      "Train  31\n",
      "Train  32\n",
      "Train  33\n",
      "Train  34\n",
      "Train  35\n",
      "Train  36\n",
      "Train  37\n",
      "Train  38\n",
      "Train  39\n",
      "Train  40\n",
      "Train  41\n",
      "Train  42\n",
      "Train  43\n",
      "Train  44\n",
      "Train  45\n",
      "Train  46\n",
      "Train  47\n",
      "Train  48\n",
      "Train  49\n",
      "Train  50\n",
      "Train  51\n",
      "Train  52\n",
      "Train  53\n",
      "Train  54\n",
      "Train  55\n",
      "Train  56\n",
      "Train  57\n",
      "Train  58\n",
      "Train  59\n",
      "Train  60\n",
      "Train  61\n",
      "Train  62\n",
      "Train  63\n",
      "Train  64\n",
      "Train  65\n",
      "Train  66\n",
      "Train  67\n",
      "Train  68\n",
      "Train  69\n",
      "Train  70\n",
      "Train  71\n",
      "Train  72\n",
      "Train  73\n",
      "Train  74\n",
      "Train  75\n",
      "Train  76\n",
      "Train  77\n",
      "Train  78\n",
      "Train  79\n",
      "Train  80\n",
      "Train  81\n",
      "Train  82\n",
      "Train  83\n",
      "Train  84\n",
      "Train  85\n",
      "Train  86\n",
      "Train  87\n",
      "Train  88\n",
      "Train  89\n",
      "Train  90\n",
      "Train  91\n",
      "Train  92\n",
      "Train  93\n",
      "Train  94\n",
      "Train  95\n",
      "Train  96\n",
      "Train  97\n",
      "Train  98\n",
      "Train  99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model.train(corpus, total_examples=len(corpus), epochs=1)\n",
    "    print('Train ', i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "model.save('./Word2vec_entraine.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def word2vec_generator(texts, model, vector_size):\n",
    "    dict_word2vec = {}\n",
    "    for index, word_list in enumerate(texts):\n",
    "        arr = np.array([0.0 for i in range(0, vector_size)])\n",
    "        nb_word = 0\n",
    "        for word in word_list:\n",
    "            try:\n",
    "                arr += model[word]\n",
    "                nb_word = nb_word + 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if (len(word_list) == 0):\n",
    "            dict_word2vec[index] = arr\n",
    "        else:\n",
    "            dict_word2vec[index] = arr / nb_word\n",
    "    df_word2vec = pd.DataFrame(dict_word2vec).T\n",
    "    return df_word2vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "corpus_train_tokens = pd.Series(train_documents).apply(lambda line: gensim.utils.simple_preprocess((line)))\n",
    "corpus_test_tokens = pd.Series(test_documents).apply(lambda line: gensim.utils.simple_preprocess((line)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "model_wv_entraine = gensim.models.Word2Vec.load('./Word2vec_entraine.h5')\n",
    "vector_size = model_wv_entraine.vector_size\n",
    "corpus_train_wv_entraine = word2vec_generator(corpus_train_tokens, model_wv_entraine.wv, vector_size)\n",
    "corpus_test_wv_entraine = word2vec_generator(corpus_test_tokens, model_wv_entraine.wv, vector_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## RF #############\n",
      "Cross-validation accuracy: 0.1904 (+/- 0.0221)\n",
      "\n",
      "################## KNN #############\n",
      "Cross-validation accuracy: 0.3432 (+/- 0.0705)\n",
      "\n",
      "################## MLP #############\n",
      "Cross-validation accuracy: 0.0094 (+/- 0.0082)\n",
      "\n",
      "################## OVSR #############\n",
      "Cross-validation accuracy: 0.7440 (+/- 0.0274)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(corpus_train_wv_entraine, train_labels, corpus_test_wv_entraine, test_labels, algos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}